{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMAC SHA256 Hashing Using Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "import hmac\n",
    "import re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Union, List\n",
    "import subprocess\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load NYU provided secret key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('<path to file with key>') as infile:\n",
    "    key = bytes(infile.read().strip(), 'utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_GPG_COMMAND = 'gpg --output {outfile} --encrypt --trusted-key {gpg} --recipient {gpg} {infile}'\n",
    "\n",
    "\n",
    "def _standard_string_cleaning(value: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a value, removes all punctuation and, reduces spaces to single space, calls strip\n",
    "    \n",
    "    Args:\n",
    "       value: String value to be cleaned\n",
    "       \n",
    "    Returns:\n",
    "       Cleaned string\n",
    "    \"\"\"\n",
    "    return re.sub(r'\\s{2,}', ' ', re.sub(r'[^A-Za-z0-9\\s]+', '', value)).strip()\n",
    "\n",
    "\n",
    "def clean_name(name_value: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a name value, remove non-alpha characters, reduce multiple spaces, and trim\n",
    "    \n",
    "    Args:\n",
    "        name_value: Name value to be cleaned\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned name as string\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^A-Z\\s]+', '', _standard_string_cleaning(name_value).upper())\n",
    "\n",
    "\n",
    "def clean_ssn(ssn_value: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a SSN value, remove non-alpha characters, reduce multiple spaces, and trim\n",
    "    \n",
    "    Args:\n",
    "        ssn_value: SSN value as string\n",
    "        \n",
    "    Returns:\n",
    "        Cleaned SSN as string\n",
    "    \"\"\"\n",
    "    return re.sub(r'[^0-9\\s]+', '', _standard_string_cleaning(ssn_value))\n",
    "    \n",
    "    \n",
    "def hash_value(value: str, key: bytes) -> str:\n",
    "    \"\"\"\n",
    "    Apply HMAC SHA 256 to an individual value and return the hexdigest\n",
    "    \n",
    "    Args:\n",
    "        value: String representation of value\n",
    "        key: Bytes object representing hash key\n",
    "        \n",
    "    Returns:\n",
    "        Hexdigest as string\n",
    "    \"\"\"\n",
    "    return hmac.new(key, bytes(value, 'utf-8'), digestmod=hashlib.sha256).hexdigest()\n",
    "\n",
    "\n",
    "def create_hashed_unique_value_dict(df: pd.DataFrame, col: str, typ: str, key: bytes) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Create dict with original value as key and hashed value as dict\n",
    "    \n",
    "    Args:\n",
    "        df: Pandas DataFrame\n",
    "        col: String name of column/series\n",
    "        typ: name or ssn\n",
    "        key: Encryption key as bytes object\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with original value as key and encrypted value as value\n",
    "        \n",
    "    \"\"\"\n",
    "    unique_values = df[col].unique()\n",
    "    func = {'name': clean_name, 'ssn': clean_ssn}[typ]\n",
    "    return {value: hash_value(func(value), key) for value in unique_values}\n",
    "    \n",
    "    \n",
    "def encrypt_csv(filepath: Union[str, Path], \n",
    "                outpath: Union[str, Path],\n",
    "                columns: List[Dict[str, str]], \n",
    "                key: bytes, \n",
    "                gpg_key_name: str, sep: str=',') -> bool:\n",
    "    \"\"\"\n",
    "    Takes a CSV and encrypts fields given a list of dictionaries {col: name or ssn},\n",
    "    serializes to csv then encrypts via gpg\n",
    "    \n",
    "    Args:\n",
    "        filepath: String or Path object representing file path\n",
    "        outpath: String or Path object to output final product\n",
    "        collumns: List of tuples with column name as element 0 and encrypt category (name or ssn) as element 1, only give target columns\n",
    "        key: Encryption key\n",
    "        gpg: gpg key name to pull from file system (assumes you have imported key using gpg)\n",
    "        \n",
    "    Keyword Args:\n",
    "        sep: Delimiter to use, defaults to comma\n",
    "        \n",
    "    Returns:\n",
    "        Boolean indicating success\n",
    "    \"\"\"\n",
    "    outpath = Path(outpath)\n",
    "    tmp_csv_path = outpath.parent / 'tmp_encrypt.csv'\n",
    "    df = pd.read_csv(filepath, dtype=str, sep=sep)\n",
    "    for col_details in columns:\n",
    "        df[col_details[0]] = df[col_details[0]].replace(create_hashed_unique_value_dict(df, *col_details, key))\n",
    "    df.to_csv(tmp_csv_path, index=0)\n",
    "    run = subprocess.run(_GPG_COMMAND.format(gpg=gpg_key_name, outfile=outpath.as_posix() , infile=tmp_csv_path.as_posix()).split(), capture_output=True)\n",
    "    if run.returncode != 0:\n",
    "        print(run.stderr)\n",
    "        raise RuntimeError(\"Failed to encrypt\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is intended to provide a one function call to encrypt the appropriate fields and the overall file.  The expected parameters, in order, are:\n",
    "\n",
    "```filepath```: The file path to your target file\n",
    "```outpath```: The file path to write the final encrypted path\n",
    "```columns```: A list of tuples, where the first value is the column name, and the second value is what data type to encrypt\n",
    "```key```: Hash key provided by Coleridge\n",
    "```gpg```: Public key for file encryption\n",
    "\n",
    "KEYWORD (OPTIONAL):\n",
    "\n",
    "```sep```: Delimiter for input file, defaults to comma\n",
    "\n",
    "```python\n",
    "encrypt_csv('<input file path>', '<encrypted file output path>', [('SSN', 'ssn'), ('first_name', 'name'), ('last_name', 'name')], '<hash key>', '<gpg key>')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXAMPLE**\n",
    "\n",
    "Let's encrypt a csv with family information for a TANF household.  In this case, the data provided was ```tab``` delimited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encrypt_csv('/home/user/secured_data/tanf_family_data.csv', \n",
    "            '/home/user/secured_data/tanf_family_encrypted', \n",
    "            [('RPT_SSN_1', 'ssn'), ('Recipient_First_Name', 'name')], \n",
    "            'XXXX|XXXX|XXXX|XXXX', \n",
    "            '5FED9A4FC02ADD64', \n",
    "            sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
